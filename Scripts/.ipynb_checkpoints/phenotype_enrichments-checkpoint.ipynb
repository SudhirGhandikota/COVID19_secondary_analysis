{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '/path/to/git/repository'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# parsing experimental factor ontology for child traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# method to verify if a given EFO trait/term is obsolete\n",
    "def is_obsolete(lines,index):\n",
    "    replaced_ids = []\n",
    "    last_index = len(lines)\n",
    "    while(True):\n",
    "        if lines[index].startswith(\"[Term]\") or index==last_index or lines[index].startswith(\"[Typedef]\"):\n",
    "            return False\n",
    "        if lines[index].startswith(\"is_obsolete\"):\n",
    "            return True\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_is_a(line):\n",
    "    #is_a: GO:0000732 ! strand displacement\n",
    "    # is_a: EFO:0003892 ! pulmonary function measurement\n",
    "    # splits = line.split(\":\")\n",
    "    parent = line.split(\" ! \")[1]\n",
    "    return parent.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# this function returns list of alternate ID's for a specific term\n",
    "def get_alt_id(lines,index):\n",
    "    alt_ids = []\n",
    "    while(True):\n",
    "        if lines[index].startswith(\"alt_id\"):\n",
    "            splits = lines[index].strip().split(\":\")\n",
    "            if len(splits)>2:\n",
    "                term_id = splits[1] + \":\" + splits[2]\n",
    "            else:\n",
    "                term_id = splits[1]\n",
    "            alt_ids.append(term_id.strip())\n",
    "            index = index+1\n",
    "        else:\n",
    "            break\n",
    "    return alt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# this function parses all the parent terms of a given term\n",
    "def getParents(lines,index):\n",
    "    parents = []\n",
    "    last_index = len(lines)\n",
    "    while(True): #looping till next term starts\n",
    "        if index==last_index or lines[index].startswith(\"[Term]\") or lines[index].startswith(\"[Typedef]\"):\n",
    "            break\n",
    "        else:\n",
    "            if lines[index].startswith(\"is_a\"):\n",
    "                parent = get_is_a(lines[index])\n",
    "                if parent is not None:\n",
    "                    parents.append(parent)\n",
    "                index = index + 1\n",
    "            else:\n",
    "                index = index + 1\n",
    "    return parents[::-1] # returning parents in the descending order of their distance from root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_name(line):\n",
    "    #id: EFO:0000001\n",
    "    splits = line.split(\":\")\n",
    "    term_name = splits[1]+\":\"+splits[2]\n",
    "    return term_name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# this function performs the fisher's exact test for overlap between two sets of genes\n",
    "def fisher_test(geneset1, geneset2):\n",
    "    overlap = set.intersection(set(geneset1), set(geneset2))\n",
    "    if len(overlap) ==0:\n",
    "        return set(), 1.0\n",
    "    a = len(overlap)\n",
    "    b = len(geneset1) - len(overlap)\n",
    "    c = len(geneset2) - len(overlap)\n",
    "    d = 20000 - (len(geneset1) + len(geneset2) - len(overlap))\n",
    "    result = stats.fisher_exact([[a,b],[c,d]])\n",
    "    fet = '{:0.3e}'.format(result[1])\n",
    "    return overlap, float(fet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# computes adjusted p-values\n",
    "def calc_adjp(pvals):\n",
    "    \"\"\"Benjamini-Hochberg p-value correction for multiple hypothesis testing.\"\"\"\n",
    "    pvals = np.asfarray(pvals)\n",
    "    descend_p = pvals.argsort()[::-1]\n",
    "    orig = descend_p.argsort()\n",
    "    steps = float(len(pvals)) / np.arange(len(pvals), 0, -1)\n",
    "    q = np.minimum(1, np.minimum.accumulate(steps * pvals[descend_p]))\n",
    "    return q[orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def SplitData(df,target_columns,separator):\n",
    "    new_rows = []\n",
    "    df.apply(splitListToRows,axis=1,args=(new_rows,target_columns,separator))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "#method to split columns having multiple values to multiple rows\n",
    "def splitListToRows(row,row_accumulator,target_columns,separator):\n",
    "    split_rows = []\n",
    "    for target_column in target_columns:\n",
    "        split_rows.append(row[target_column].split(separator))\n",
    "    #separate for multiple columns\n",
    "    for i in range(len(split_rows[0])):#looping over each split value\n",
    "        new_row = row.to_dict()\n",
    "        for j in range(len(split_rows)):#looping over each column\n",
    "            #print(split_rows[j][i].strip())\n",
    "            new_row[target_columns[j]] = split_rows[j][i].strip()\n",
    "        row_accumulator.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520485"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efo_lines = open(os.path.join(dirpath, 'input_data/other data/efo.obo.txt'), \"r\").readlines()\n",
    "len(efo_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parsing EFO OBO file\n",
    "efo = {}\n",
    "parent_dict = defaultdict(list)\n",
    "child_dict = defaultdict(list)\n",
    "i=0\n",
    "while i<len(efo_lines):\n",
    "    if efo_lines[i].startswith(\"[Term]\") and not is_obsolete(efo_lines,i+1) and 'EFO' in efo_lines[i+1]:\n",
    "        term_id = get_name(efo_lines[i+1])\n",
    "        term_name = efo_lines[i+2].split(\":\")[1].strip()\n",
    "        efo[term_id] = term_name\n",
    "        parents = getParents(efo_lines,i+1)\n",
    "        \n",
    "        #updating the child dict of the parents\n",
    "        for parent in parents:\n",
    "            child_dict[parent].append(term_name)\n",
    "            parent_dict[term_name].append(parent)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9605 9531 3071\n"
     ]
    }
   ],
   "source": [
    "print(len(efo), len(parent_dict), len(child_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189811, 38)\n"
     ]
    }
   ],
   "source": [
    "# reading GWAS Catalog data\n",
    "GWAS_df = pd.read_csv(os.path.join(dirpath, 'input_data/other data/gwas_catalog_v1.0.2-associations_e100_r2020-07-14.tsv'),sep = \"\\t\")\n",
    "print(GWAS_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189558, 26)\n"
     ]
    }
   ],
   "source": [
    "# removing unwanted columns\n",
    "GWAS_df.drop(['DATE ADDED TO CATALOG', 'PUBMEDID', 'FIRST AUTHOR', 'DATE', 'JOURNAL', 'LINK', 'STUDY',\n",
    "             'INITIAL SAMPLE SIZE', 'REPLICATION SAMPLE SIZE', 'GENOTYPING TECHNOLOGY', 'STUDY ACCESSION',\n",
    "             'PLATFORM [SNPS PASSING QC]'], axis = 1, inplace=True)\n",
    "GWAS_df.drop_duplicates(inplace=True)\n",
    "print(GWAS_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199272, 26)\n"
     ]
    }
   ],
   "source": [
    "GWAS_df['MAPPED_TRAIT'] = GWAS_df['MAPPED_TRAIT'].astype(str)\n",
    "GWAS_df['MAPPED_GENE'] = GWAS_df['MAPPED_GENE'].astype(str)\n",
    "\n",
    "GWAS_df = SplitData(GWAS_df,[\"MAPPED_GENE\"],\", \") #splitting multiple mapped genes\n",
    "GWAS_df = SplitData(GWAS_df,['MAPPED_TRAIT'],', ')#splitting multiple mapped traits\n",
    "\n",
    "# removing intergenic associations\n",
    "GWAS_df = GWAS_df[GWAS_df['INTERGENIC']==0]\n",
    "print(GWAS_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving filtered GWAS Catalog data\n",
    "# GWAS_df.to_csv(os.path.join(dirpath, \"input_data/other data/GWAS_Catalog_associations_fil.txt\"), sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# GWAS Catalog Trait enrichments among conserved DEG signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrichments of trait-associated genes in a given DEG\n",
    "def trait_enrichments(genes, geneset_name):\n",
    "    enc_results = []\n",
    "    \n",
    "    for trait in all_traits:\n",
    "        trait_list = [trait]\n",
    "        if trait in child_dict:\n",
    "            trait_list = trait_list + child_dict[trait]\n",
    "        trait_genes = set(GWAS_df[GWAS_df['MAPPED_TRAIT'].map(lambda trait: \n",
    "                                                       trait in trait_list)]['MAPPED_GENE'].to_list())\n",
    "        if len(trait_genes)==0:\n",
    "            continue\n",
    "        overlap, fet = fisher_test(genes, trait_genes)\n",
    "        if len(overlap)==0:\n",
    "            continue\n",
    "        logp = -np.log10(fet)\n",
    "        enc_results.append([trait, len(child_dict[trait]), len(trait_genes), geneset_name, \n",
    "                            len(genes), len(overlap), \",\".join(list(overlap)), fet, logp])\n",
    "    enc_results = pd.DataFrame(enc_results, columns = [\"Trait\", \"# Child Traits\", \"# Mapped genes\",\n",
    "                                                       \"DEG\", \"DEG_Size\", \"Overlap_Size\", \"Overlap\",\n",
    "                                                       \"P-value(FET)\", \"logP\"])\n",
    "    enc_results['q-val'] = calc_adjp(enc_results['P-value(FET)'].to_list())\n",
    "    enc_results['logq'] = -np.log10(enc_results['q-val'])\n",
    "    return enc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833 634 1467\n"
     ]
    }
   ],
   "source": [
    "# reading conserved COVID DEGs\n",
    "covid19_cons_up = pd.read_csv(os.path.join(dirpath, \"input_data/SARS-CoV2_DEGS/Conserved_UP.txt\"), header = None)\n",
    "covid19_cons_up = covid19_cons_up[0].to_list()\n",
    "covid19_cons_dn = pd.read_csv(os.path.join(dirpath, \"input_data/SARS-CoV2_DEGS/Conserved_DN.txt\"), header = None)\n",
    "covid19_cons_dn = covid19_cons_dn[0].to_list()\n",
    "covid19_cons_degs = set.union(set(list(covid19_cons_up)), set(list(covid19_cons_dn)))\n",
    "print(len(covid19_cons_up), len(covid19_cons_dn), len(covid19_cons_degs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635\n"
     ]
    }
   ],
   "source": [
    "all_traits = GWAS_df['MAPPED_TRAIT'].unique()\n",
    "print(len(all_traits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2687\n"
     ]
    }
   ],
   "source": [
    "all_child_traits = []\n",
    "for trait in all_traits:\n",
    "    all_child_traits.extend(child_dict[trait])\n",
    "all_child_traits = set(all_child_traits)\n",
    "print(len(all_child_traits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 11) (667, 11) (1209, 11)\n"
     ]
    }
   ],
   "source": [
    "enc_results_cons_up = trait_enrichments(covid19_cons_up, 'COVID19_Up(Conserved)')\n",
    "enc_results_cons_dn = trait_enrichments(covid19_cons_dn, 'COVID19_DN(Conserved)')\n",
    "enc_results_cons_both = trait_enrichments(covid19_cons_degs, 'COVID19_DEG(Both)')\n",
    "print(enc_results_cons_up.shape, enc_results_cons_dn.shape, enc_results_cons_both.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplemental Table S8\n",
    "enc_results_cons_com = pd.concat([enc_results_cons_up, enc_results_cons_dn, enc_results_cons_both], axis = 0)\n",
    "#enc_results_cons_com.to_csv('Enc_results/cons_GWAS_overlap.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# GWAS Catalog trait enrichments in SARS-CoV-2 gene modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors: 8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors:\",mp.cpu_count())\n",
    "\n",
    "from time import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichment_handler(cid):\n",
    "    print(\"*\"*5, cid, \"*\"*5)\n",
    "    cluster_genes = node_stats[node_stats['MCL cluster']==cid]['name'].to_list()\n",
    "    enc_results_cluster = trait_enrichments(cluster_genes, cid)\n",
    "    return enc_results_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>node1 gene ID</th>\n",
       "      <th>MCL cluster</th>\n",
       "      <th>Conserved (Y/N)</th>\n",
       "      <th>SARS-CoV-2 Interacting Protein</th>\n",
       "      <th>SARS-CoV-2 PPI (Y/N)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADAR</td>\n",
       "      <td>103</td>\n",
       "      <td>C-1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANAPC11</td>\n",
       "      <td>51529</td>\n",
       "      <td>C-1</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  node1 gene ID MCL cluster Conserved (Y/N)  \\\n",
       "0     ADAR            103         C-1             yes   \n",
       "1  ANAPC11          51529         C-1             yes   \n",
       "\n",
       "  SARS-CoV-2 Interacting Protein SARS-CoV-2 PPI (Y/N)  \n",
       "0                            NaN                   no  \n",
       "1                            NaN                   no  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_stats = pd.read_csv(os.path.join(dirpath,'input_data/SARS-CoV-2-Cons_MCL_Clusters.txt'), sep = \"\\t\")\n",
    "node_stats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# removing unassigned genes\n",
    "node_stats = node_stats[-node_stats['MCL cluster'].isna()]\n",
    "# candidate clusters\n",
    "selected_clusters = list({cid:size for cid,size in dict(Counter(node_stats['MCL cluster'])).items() if size > 4}.keys())\n",
    "print(len(selected_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** C-9 *****\n",
      "***** C-7 *****\n",
      "***** C-13 *****\n",
      "***** C-1 *****\n",
      "***** C-5 *****\n",
      "***** C-11 *****\n",
      "***** C-3 *****\n",
      "***** C-15 *****\n",
      "***** C-8 *****\n",
      "***** C-6 *****\n",
      "***** C-16 *****\n",
      "***** C-14 *****\n",
      "***** C-12 *****\n",
      "***** C-10 *****\n",
      "***** C-4 *****\n",
      "***** C-2 *****\n",
      "***** C-17 *****\n",
      "***** C-19 *****\n",
      "***** C-22 *****\n",
      "***** C-24 *****\n",
      "***** C-27 *****\n",
      "***** C-29 *****\n",
      "***** C-35 *****\n",
      "***** C-25 *****\n",
      "***** C-18 *****\n",
      "***** C-21 *****\n",
      "***** C-28 *****\n",
      "***** C-23 *****\n",
      "***** C-26 *****\n",
      "***** C-34 *****\n",
      "***** C-20 *****\n",
      "***** C-30 *****\n",
      "***** C-31 *****\n",
      "***** C-33 *****\n",
      "***** C-32 *****\n"
     ]
    }
   ],
   "source": [
    "#initiating multiprocessing pool object\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "results = pool.map(enrichment_handler, [cid for cid in selected_clusters])\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3167, 11)\n"
     ]
    }
   ],
   "source": [
    "enc_results = pd.concat(results, axis = 0)\n",
    "print(enc_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplemental Table S13\n",
    "# enc_results.to_csv('Enc_results/SARS_COV_2_Module_GWAS_overlap.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
